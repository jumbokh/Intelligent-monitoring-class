{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IMAGEAI-ObjectDetectionTrain-HoloLens.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jumbokh/Intelligent-monitoring-class/blob/main/notebooks/IMAGEAI_ObjectDetectionTrain_HoloLens.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXFProzuNCFz"
      },
      "source": [
        "## 1. Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klYO3yuivSRI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "41ea98f3-569f-400c-d592-08a2b217e8f9"
      },
      "source": [
        "!pip3 install albumentations --upgrade"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting albumentations\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/c4/a1e6ac237b5a27874b01900987d902fe83cc469ebdb09eb72a68c4329e78/albumentations-0.4.3.tar.gz (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 9.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from albumentations) (1.17.5)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from albumentations) (1.4.1)\n",
            "Collecting imgaug<0.2.7,>=0.2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/2e/748dbb7bb52ec8667098bae9b585f448569ae520031932687761165419a2/imgaug-0.2.6.tar.gz (631kB)\n",
            "\u001b[K     |████████████████████████████████| 634kB 53.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: PyYAML in /usr/local/lib/python3.6/dist-packages (from albumentations) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: opencv-python>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from albumentations) (4.1.2.30)\n",
            "Requirement already satisfied, skipping upgrade: scikit-image>=0.11.0 in /usr/local/lib/python3.6/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations) (0.16.2)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.4)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (3.1.2)\n",
            "Requirement already satisfied, skipping upgrade: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.4.1)\n",
            "Requirement already satisfied, skipping upgrade: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (6.2.2)\n",
            "Requirement already satisfied, skipping upgrade: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (1.1.1)\n",
            "Requirement already satisfied, skipping upgrade: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (4.4.1)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.6.1)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.4.6)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (42.0.2)\n",
            "Building wheels for collected packages: albumentations, imgaug\n",
            "  Building wheel for albumentations (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for albumentations: filename=albumentations-0.4.3-cp36-none-any.whl size=60764 sha256=70f12409bf9fd83c75304e17372d711c06eb8b6f22dc19df2bc6bc22db6eec65\n",
            "  Stored in directory: /root/.cache/pip/wheels/20/16/8e/d3bec34bf30adff30929226f0b83cc8c005b5af131f51db9d0\n",
            "  Building wheel for imgaug (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imgaug: filename=imgaug-0.2.6-cp36-none-any.whl size=654020 sha256=068ed61e964d3dc113dbfc0cb202fdb7d81dcd67eb27d6391321e50051de6cf2\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/ec/48/0d25896c417b715af6236dbcef8f0bed136a1a5e52972fc6d0\n",
            "Successfully built albumentations imgaug\n",
            "Installing collected packages: imgaug, albumentations\n",
            "  Found existing installation: imgaug 0.2.9\n",
            "    Uninstalling imgaug-0.2.9:\n",
            "      Successfully uninstalled imgaug-0.2.9\n",
            "  Found existing installation: albumentations 0.1.12\n",
            "    Uninstalling albumentations-0.1.12:\n",
            "      Successfully uninstalled albumentations-0.1.12\n",
            "Successfully installed albumentations-0.4.3 imgaug-0.2.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65xxaL7NIzMi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "257710f4-1a93-42a9-f140-33b42a39119f"
      },
      "source": [
        "!pip install -U tensorflow keras opencv-python\n",
        "!pip3 install imageai --upgrade\n",
        "# If you experience '_TfDeviceCaptureOp' object has no attribute '_set_device_from_string' error in Google Colab, it is due to a bug in Tensorflow. You can solve this by installing Tensorflow GPU 1.13.1. \n",
        "!pip3 install tensorflow-gpu==1.13.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/d4/c0cd1057b331bc38b65478302114194bd8e1b9c2bbc06e300935c0e93d90/tensorflow-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl (421.8MB)\n",
            "\u001b[K     |████████████████████████████████| 421.8MB 41kB/s \n",
            "\u001b[?25hCollecting keras\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n",
            "\u001b[K     |████████████████████████████████| 378kB 48.0MB/s \n",
            "\u001b[?25hRequirement already up-to-date: opencv-python in /usr/local/lib/python3.6/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.1.8)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.9.0)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.17.5)\n",
            "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 53.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.33.6)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.2)\n",
            "Collecting tensorboard<2.2.0,>=2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/23/53ffe290341cd0855d595b0a2e7485932f473798af173bbe3a584b99bb06/tensorboard-2.1.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 55.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.8.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow) (42.0.2)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (0.16.0)\n",
            "Collecting google-auth<2,>=1.6.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8d/5f/a1a02695b96d0e09c38abf7d1576b137979cea3d060d60891622cf61276d/google_auth-1.10.1-py2.py3-none-any.whl (76kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 12.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2019.11.28)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (4.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.2.7)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.8)\n",
            "\u001b[31mERROR: tensorboard 2.1.0 has requirement grpcio>=1.24.3, but you'll have grpcio 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement google-auth~=1.4.0, but you'll have google-auth 1.10.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorflow-estimator, google-auth, tensorboard, tensorflow, keras\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "  Found existing installation: google-auth 1.4.2\n",
            "    Uninstalling google-auth-1.4.2:\n",
            "      Successfully uninstalled google-auth-1.4.2\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: tensorflow 1.15.0\n",
            "    Uninstalling tensorflow-1.15.0:\n",
            "      Successfully uninstalled tensorflow-1.15.0\n",
            "  Found existing installation: Keras 2.2.5\n",
            "    Uninstalling Keras-2.2.5:\n",
            "      Successfully uninstalled Keras-2.2.5\n",
            "Successfully installed google-auth-1.10.1 keras-2.3.1 tensorboard-2.1.0 tensorflow-2.1.0 tensorflow-estimator-2.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting imageai\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/99/4023e191a343fb23f01ae02ac57a5ca58037c310e8d8c62f87638a3bafc7/imageai-2.1.5-py3-none-any.whl (180kB)\n",
            "\r\u001b[K     |█▉                              | 10kB 27.8MB/s eta 0:00:01\r\u001b[K     |███▋                            | 20kB 6.1MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 30kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 40kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████████                       | 51kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 61kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 71kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 81kB 10.2MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 92kB 11.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 102kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 112kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 122kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 133kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 143kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 153kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 163kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 174kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 184kB 9.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: pillow in /usr/local/lib/python3.6/dist-packages (from imageai) (6.2.2)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from imageai) (1.17.5)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.6/dist-packages (from imageai) (3.1.2)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from imageai) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from imageai) (2.8.0)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imageai) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imageai) (2.6.1)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imageai) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imageai) (2.4.6)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from h5py->imageai) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->imageai) (42.0.2)\n",
            "Installing collected packages: imageai\n",
            "Successfully installed imageai-2.1.5\n",
            "Collecting tensorflow-gpu==1.13.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/b1/0ad4ae02e17ddd62109cd54c291e311c4b5fd09b4d0678d3d6ce4159b0f0/tensorflow_gpu-1.13.1-cp36-cp36m-manylinux1_x86_64.whl (345.2MB)\n",
            "\u001b[K     |████████████████████████████████| 345.2MB 21kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.17.5)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.2.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.9.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (3.10.0)\n",
            "Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367kB)\n",
            "\u001b[K     |████████████████████████████████| 368kB 43.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.1.0)\n",
            "Collecting tensorboard<1.14.0,>=1.13.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/39/bdd75b08a6fba41f098b6cb091b9e8c7a80e1b4d679a581a0ccd17b10373/tensorboard-1.13.1-py3-none-any.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 50.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.8.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.33.6)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.0.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.13.1) (42.0.2)\n",
            "Collecting mock>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/05/d2/f94e68be6b17f46d2c353564da56e6fb89ef09faeeff3313a046cb810ca9/mock-3.0.5-py2.py3-none-any.whl\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (0.16.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (3.1.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.13.1) (2.8.0)\n",
            "\u001b[31mERROR: tensorflow 2.1.0 has requirement tensorboard<2.2.0,>=2.1.0, but you'll have tensorboard 1.13.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.1.0 has requirement tensorflow-estimator<2.2.0,>=2.1.0rc0, but you'll have tensorflow-estimator 1.13.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: mock, tensorflow-estimator, tensorboard, tensorflow-gpu\n",
            "  Found existing installation: tensorflow-estimator 2.1.0\n",
            "    Uninstalling tensorflow-estimator-2.1.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.1.0\n",
            "  Found existing installation: tensorboard 2.1.0\n",
            "    Uninstalling tensorboard-2.1.0:\n",
            "      Successfully uninstalled tensorboard-2.1.0\n",
            "Successfully installed mock-3.0.5 tensorboard-1.13.1 tensorflow-estimator-1.13.0 tensorflow-gpu-1.13.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2g8UU8xGNPc_"
      },
      "source": [
        "## 2. Download Dataset and unzip the file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5CfbswTJPLs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "df9aad65-3938-4a25-8810-c6a6dd468603"
      },
      "source": [
        "!wget https://github.com/OlafenwaMoses/ImageAI/releases/download/essential-v4/hololens.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-17 09:02:38--  https://github.com/OlafenwaMoses/ImageAI/releases/download/essential-v4/hololens.zip\n",
            "Resolving github.com (github.com)... 140.82.118.3\n",
            "Connecting to github.com (github.com)|140.82.118.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/125932201/cd011f80-b2ad-11e9-9fa9-b04b13c50ea3?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200117%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200117T090238Z&X-Amz-Expires=300&X-Amz-Signature=e32ec70440d4d6d96ea51c5c22191864a1caa1169e3cfa319de375f4cb5f1ab0&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dhololens.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2020-01-17 09:02:38--  https://github-production-release-asset-2e65be.s3.amazonaws.com/125932201/cd011f80-b2ad-11e9-9fa9-b04b13c50ea3?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200117%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200117T090238Z&X-Amz-Expires=300&X-Amz-Signature=e32ec70440d4d6d96ea51c5c22191864a1caa1169e3cfa319de375f4cb5f1ab0&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dhololens.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.160.203\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.160.203|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2348959 (2.2M) [application/octet-stream]\n",
            "Saving to: ‘hololens.zip’\n",
            "\n",
            "\rhololens.zip          0%[                    ]       0  --.-KB/s               \rhololens.zip          5%[>                   ] 135.58K   540KB/s               \rhololens.zip         53%[=========>          ]   1.20M  2.39MB/s               \rhololens.zip        100%[===================>]   2.24M  4.42MB/s    in 0.5s    \n",
            "\n",
            "2020-01-17 09:02:39 (4.42 MB/s) - ‘hololens.zip’ saved [2348959/2348959]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4l4mfIo4AzaU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "1a3d71a5-6ce0-4a4b-af5c-e55efe673a9a"
      },
      "source": [
        "!wget https://github.com/picashuo/ImageData/releases/download/essential-v5/hololens.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-17 09:02:42--  https://github.com/picashuo/ImageData/releases/download/essential-v5/hololens.zip\n",
            "Resolving github.com (github.com)... 140.82.118.3\n",
            "Connecting to github.com (github.com)|140.82.118.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/203287045/4d214a80-c525-11e9-8b63-39e24e55d4fb?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200117%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200117T090242Z&X-Amz-Expires=300&X-Amz-Signature=c974f7643758a10cc426443d3530389ee6816c1997be93fce9d1cf8fc6c5bdb9&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dhololens.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2020-01-17 09:02:42--  https://github-production-release-asset-2e65be.s3.amazonaws.com/203287045/4d214a80-c525-11e9-8b63-39e24e55d4fb?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200117%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200117T090242Z&X-Amz-Expires=300&X-Amz-Signature=c974f7643758a10cc426443d3530389ee6816c1997be93fce9d1cf8fc6c5bdb9&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dhololens.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.230.3\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.230.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9051805 (8.6M) [application/octet-stream]\n",
            "Saving to: ‘hololens.zip.1’\n",
            "\n",
            "hololens.zip.1      100%[===================>]   8.63M  11.3MB/s    in 0.8s    \n",
            "\n",
            "2020-01-17 09:02:43 (11.3 MB/s) - ‘hololens.zip.1’ saved [9051805/9051805]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOPM87BzJi0s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c7975aec-59a9-4252-a2df-caa6f3e310b5"
      },
      "source": [
        "!unzip hololens.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  hololens.zip\n",
            "   creating: hololens/\n",
            "  inflating: hololens/hololens_test.pkl  \n",
            "  inflating: hololens/hololens_train.pkl  \n",
            "   creating: hololens/train/\n",
            "   creating: hololens/train/annotations/\n",
            "  inflating: hololens/train/annotations/image (1).xml  \n",
            "  inflating: hololens/train/annotations/image (10).xml  \n",
            "  inflating: hololens/train/annotations/image (100).xml  \n",
            "  inflating: hololens/train/annotations/image (101).xml  \n",
            "  inflating: hololens/train/annotations/image (102).xml  \n",
            "  inflating: hololens/train/annotations/image (103).xml  \n",
            "  inflating: hololens/train/annotations/image (104).xml  \n",
            "  inflating: hololens/train/annotations/image (105).xml  \n",
            "  inflating: hololens/train/annotations/image (106).xml  \n",
            "  inflating: hololens/train/annotations/image (107).xml  \n",
            "  inflating: hololens/train/annotations/image (108).xml  \n",
            "  inflating: hololens/train/annotations/image (109).xml  \n",
            "  inflating: hololens/train/annotations/image (11).xml  \n",
            "  inflating: hololens/train/annotations/image (110).xml  \n",
            "  inflating: hololens/train/annotations/image (111).xml  \n",
            "  inflating: hololens/train/annotations/image (112).xml  \n",
            "  inflating: hololens/train/annotations/image (113).xml  \n",
            "  inflating: hololens/train/annotations/image (114).xml  \n",
            "  inflating: hololens/train/annotations/image (115).xml  \n",
            "  inflating: hololens/train/annotations/image (116).xml  \n",
            "  inflating: hololens/train/annotations/image (117).xml  \n",
            "  inflating: hololens/train/annotations/image (118).xml  \n",
            "  inflating: hololens/train/annotations/image (119).xml  \n",
            "  inflating: hololens/train/annotations/image (12).xml  \n",
            "  inflating: hololens/train/annotations/image (120).xml  \n",
            "  inflating: hololens/train/annotations/image (121).xml  \n",
            "  inflating: hololens/train/annotations/image (122).xml  \n",
            "  inflating: hololens/train/annotations/image (123).xml  \n",
            "  inflating: hololens/train/annotations/image (124).xml  \n",
            "  inflating: hololens/train/annotations/image (125).xml  \n",
            "  inflating: hololens/train/annotations/image (126).xml  \n",
            "  inflating: hololens/train/annotations/image (127).xml  \n",
            "  inflating: hololens/train/annotations/image (128).xml  \n",
            "  inflating: hololens/train/annotations/image (129).xml  \n",
            "  inflating: hololens/train/annotations/image (13).xml  \n",
            "  inflating: hololens/train/annotations/image (130).xml  \n",
            "  inflating: hololens/train/annotations/image (131).xml  \n",
            "  inflating: hololens/train/annotations/image (132).xml  \n",
            "  inflating: hololens/train/annotations/image (133).xml  \n",
            "  inflating: hololens/train/annotations/image (134).xml  \n",
            "  inflating: hololens/train/annotations/image (135).xml  \n",
            "  inflating: hololens/train/annotations/image (136).xml  \n",
            "  inflating: hololens/train/annotations/image (137).xml  \n",
            "  inflating: hololens/train/annotations/image (138).xml  \n",
            "  inflating: hololens/train/annotations/image (14).xml  \n",
            "  inflating: hololens/train/annotations/image (140).xml  \n",
            "  inflating: hololens/train/annotations/image (141).xml  \n",
            "  inflating: hololens/train/annotations/image (142).xml  \n",
            "  inflating: hololens/train/annotations/image (143).xml  \n",
            "  inflating: hololens/train/annotations/image (144).xml  \n",
            "  inflating: hololens/train/annotations/image (145).xml  \n",
            "  inflating: hololens/train/annotations/image (146).xml  \n",
            "  inflating: hololens/train/annotations/image (147).xml  \n",
            "  inflating: hololens/train/annotations/image (148).xml  \n",
            "  inflating: hololens/train/annotations/image (149).xml  \n",
            "  inflating: hololens/train/annotations/image (15).xml  \n",
            "  inflating: hololens/train/annotations/image (150).xml  \n",
            "  inflating: hololens/train/annotations/image (151).xml  \n",
            "  inflating: hololens/train/annotations/image (152).xml  \n",
            "  inflating: hololens/train/annotations/image (153).xml  \n",
            "  inflating: hololens/train/annotations/image (154).xml  \n",
            "  inflating: hololens/train/annotations/image (155).xml  \n",
            "  inflating: hololens/train/annotations/image (156).xml  \n",
            "  inflating: hololens/train/annotations/image (157).xml  \n",
            "  inflating: hololens/train/annotations/image (158).xml  \n",
            "  inflating: hololens/train/annotations/image (159).xml  \n",
            "  inflating: hololens/train/annotations/image (16).xml  \n",
            "  inflating: hololens/train/annotations/image (160).xml  \n",
            "  inflating: hololens/train/annotations/image (161).xml  \n",
            "  inflating: hololens/train/annotations/image (162).xml  \n",
            "  inflating: hololens/train/annotations/image (163).xml  \n",
            "  inflating: hololens/train/annotations/image (164).xml  \n",
            "  inflating: hololens/train/annotations/image (165).xml  \n",
            "  inflating: hololens/train/annotations/image (166).xml  \n",
            "  inflating: hololens/train/annotations/image (167).xml  \n",
            "  inflating: hololens/train/annotations/image (168).xml  \n",
            "  inflating: hololens/train/annotations/image (169).xml  \n",
            "  inflating: hololens/train/annotations/image (17).xml  \n",
            "  inflating: hololens/train/annotations/image (170).xml  \n",
            "  inflating: hololens/train/annotations/image (171).xml  \n",
            "  inflating: hololens/train/annotations/image (172).xml  \n",
            "  inflating: hololens/train/annotations/image (173).xml  \n",
            "  inflating: hololens/train/annotations/image (174).xml  \n",
            "  inflating: hololens/train/annotations/image (175).xml  \n",
            "  inflating: hololens/train/annotations/image (176).xml  \n",
            "  inflating: hololens/train/annotations/image (177).xml  \n",
            "  inflating: hololens/train/annotations/image (178).xml  \n",
            "  inflating: hololens/train/annotations/image (179).xml  \n",
            "  inflating: hololens/train/annotations/image (18).xml  \n",
            "  inflating: hololens/train/annotations/image (180).xml  \n",
            "  inflating: hololens/train/annotations/image (181).xml  \n",
            "  inflating: hololens/train/annotations/image (182).xml  \n",
            "  inflating: hololens/train/annotations/image (183).xml  \n",
            "  inflating: hololens/train/annotations/image (184).xml  \n",
            "  inflating: hololens/train/annotations/image (185).xml  \n",
            "  inflating: hololens/train/annotations/image (186).xml  \n",
            "  inflating: hololens/train/annotations/image (187).xml  \n",
            "  inflating: hololens/train/annotations/image (188).xml  \n",
            "  inflating: hololens/train/annotations/image (189).xml  \n",
            "  inflating: hololens/train/annotations/image (19).xml  \n",
            "  inflating: hololens/train/annotations/image (190).xml  \n",
            "  inflating: hololens/train/annotations/image (191).xml  \n",
            "  inflating: hololens/train/annotations/image (192).xml  \n",
            "  inflating: hololens/train/annotations/image (193).xml  \n",
            "  inflating: hololens/train/annotations/image (194).xml  \n",
            "  inflating: hololens/train/annotations/image (195).xml  \n",
            "  inflating: hololens/train/annotations/image (196).xml  \n",
            "  inflating: hololens/train/annotations/image (197).xml  \n",
            "  inflating: hololens/train/annotations/image (198).xml  \n",
            "  inflating: hololens/train/annotations/image (199).xml  \n",
            "  inflating: hololens/train/annotations/image (2).xml  \n",
            "  inflating: hololens/train/annotations/image (20).xml  \n",
            "  inflating: hololens/train/annotations/image (200).xml  \n",
            "  inflating: hololens/train/annotations/image (201).xml  \n",
            "  inflating: hololens/train/annotations/image (202).xml  \n",
            "  inflating: hololens/train/annotations/image (203).xml  \n",
            "  inflating: hololens/train/annotations/image (204).xml  \n",
            "  inflating: hololens/train/annotations/image (205).xml  \n",
            "  inflating: hololens/train/annotations/image (206).xml  \n",
            "  inflating: hololens/train/annotations/image (207).xml  \n",
            "  inflating: hololens/train/annotations/image (208).xml  \n",
            "  inflating: hololens/train/annotations/image (209).xml  \n",
            "  inflating: hololens/train/annotations/image (21).xml  \n",
            "  inflating: hololens/train/annotations/image (210).xml  \n",
            "  inflating: hololens/train/annotations/image (211).xml  \n",
            "  inflating: hololens/train/annotations/image (212).xml  \n",
            "  inflating: hololens/train/annotations/image (213).xml  \n",
            "  inflating: hololens/train/annotations/image (214).xml  \n",
            "  inflating: hololens/train/annotations/image (215).xml  \n",
            "  inflating: hololens/train/annotations/image (216).xml  \n",
            "  inflating: hololens/train/annotations/image (217).xml  \n",
            "  inflating: hololens/train/annotations/image (218).xml  \n",
            "  inflating: hololens/train/annotations/image (219).xml  \n",
            "  inflating: hololens/train/annotations/image (22).xml  \n",
            "  inflating: hololens/train/annotations/image (220).xml  \n",
            "  inflating: hololens/train/annotations/image (221).xml  \n",
            "  inflating: hololens/train/annotations/image (222).xml  \n",
            "  inflating: hololens/train/annotations/image (223).xml  \n",
            "  inflating: hololens/train/annotations/image (224).xml  \n",
            "  inflating: hololens/train/annotations/image (225).xml  \n",
            "  inflating: hololens/train/annotations/image (226).xml  \n",
            "  inflating: hololens/train/annotations/image (227).xml  \n",
            "  inflating: hololens/train/annotations/image (228).xml  \n",
            "  inflating: hololens/train/annotations/image (229).xml  \n",
            "  inflating: hololens/train/annotations/image (23).xml  \n",
            "  inflating: hololens/train/annotations/image (230).xml  \n",
            "  inflating: hololens/train/annotations/image (231).xml  \n",
            "  inflating: hololens/train/annotations/image (232).xml  \n",
            "  inflating: hololens/train/annotations/image (233).xml  \n",
            "  inflating: hololens/train/annotations/image (234).xml  \n",
            "  inflating: hololens/train/annotations/image (235).xml  \n",
            "  inflating: hololens/train/annotations/image (236).xml  \n",
            "  inflating: hololens/train/annotations/image (237).xml  \n",
            "  inflating: hololens/train/annotations/image (238).xml  \n",
            "  inflating: hololens/train/annotations/image (239).xml  \n",
            "  inflating: hololens/train/annotations/image (24).xml  \n",
            "  inflating: hololens/train/annotations/image (240).xml  \n",
            "  inflating: hololens/train/annotations/image (241).xml  \n",
            "  inflating: hololens/train/annotations/image (25).xml  \n",
            "  inflating: hololens/train/annotations/image (26).xml  \n",
            "  inflating: hololens/train/annotations/image (27).xml  \n",
            "  inflating: hololens/train/annotations/image (28).xml  \n",
            "  inflating: hololens/train/annotations/image (29).xml  \n",
            "  inflating: hololens/train/annotations/image (3).xml  \n",
            "  inflating: hololens/train/annotations/image (30).xml  \n",
            "  inflating: hololens/train/annotations/image (31).xml  \n",
            "  inflating: hololens/train/annotations/image (32).xml  \n",
            "  inflating: hololens/train/annotations/image (33).xml  \n",
            "  inflating: hololens/train/annotations/image (34).xml  \n",
            "  inflating: hololens/train/annotations/image (35).xml  \n",
            "  inflating: hololens/train/annotations/image (36).xml  \n",
            "  inflating: hololens/train/annotations/image (37).xml  \n",
            "  inflating: hololens/train/annotations/image (38).xml  \n",
            "  inflating: hololens/train/annotations/image (39).xml  \n",
            "  inflating: hololens/train/annotations/image (4).xml  \n",
            "  inflating: hololens/train/annotations/image (40).xml  \n",
            "  inflating: hololens/train/annotations/image (41).xml  \n",
            "  inflating: hololens/train/annotations/image (42).xml  \n",
            "  inflating: hololens/train/annotations/image (43).xml  \n",
            "  inflating: hololens/train/annotations/image (44).xml  \n",
            "  inflating: hololens/train/annotations/image (45).xml  \n",
            "  inflating: hololens/train/annotations/image (46).xml  \n",
            "  inflating: hololens/train/annotations/image (47).xml  \n",
            "  inflating: hololens/train/annotations/image (48).xml  \n",
            "  inflating: hololens/train/annotations/image (49).xml  \n",
            "  inflating: hololens/train/annotations/image (5).xml  \n",
            "  inflating: hololens/train/annotations/image (50).xml  \n",
            "  inflating: hololens/train/annotations/image (51).xml  \n",
            "  inflating: hololens/train/annotations/image (52).xml  \n",
            "  inflating: hololens/train/annotations/image (53).xml  \n",
            "  inflating: hololens/train/annotations/image (54).xml  \n",
            "  inflating: hololens/train/annotations/image (55).xml  \n",
            "  inflating: hololens/train/annotations/image (56).xml  \n",
            "  inflating: hololens/train/annotations/image (57).xml  \n",
            "  inflating: hololens/train/annotations/image (58).xml  \n",
            "  inflating: hololens/train/annotations/image (59).xml  \n",
            "  inflating: hololens/train/annotations/image (6).xml  \n",
            "  inflating: hololens/train/annotations/image (60).xml  \n",
            "  inflating: hololens/train/annotations/image (61).xml  \n",
            "  inflating: hololens/train/annotations/image (62).xml  \n",
            "  inflating: hololens/train/annotations/image (63).xml  \n",
            "  inflating: hololens/train/annotations/image (64).xml  \n",
            "  inflating: hololens/train/annotations/image (65).xml  \n",
            "  inflating: hololens/train/annotations/image (66).xml  \n",
            "  inflating: hololens/train/annotations/image (67).xml  \n",
            "  inflating: hololens/train/annotations/image (68).xml  \n",
            "  inflating: hololens/train/annotations/image (69).xml  \n",
            "  inflating: hololens/train/annotations/image (7).xml  \n",
            "  inflating: hololens/train/annotations/image (70).xml  \n",
            "  inflating: hololens/train/annotations/image (71).xml  \n",
            "  inflating: hololens/train/annotations/image (72).xml  \n",
            "  inflating: hololens/train/annotations/image (73).xml  \n",
            "  inflating: hololens/train/annotations/image (74).xml  \n",
            "  inflating: hololens/train/annotations/image (75).xml  \n",
            "  inflating: hololens/train/annotations/image (76).xml  \n",
            "  inflating: hololens/train/annotations/image (77).xml  \n",
            "  inflating: hololens/train/annotations/image (78).xml  \n",
            "  inflating: hololens/train/annotations/image (79).xml  \n",
            "  inflating: hololens/train/annotations/image (8).xml  \n",
            "  inflating: hololens/train/annotations/image (80).xml  \n",
            "  inflating: hololens/train/annotations/image (81).xml  \n",
            "  inflating: hololens/train/annotations/image (82).xml  \n",
            "  inflating: hololens/train/annotations/image (83).xml  \n",
            "  inflating: hololens/train/annotations/image (84).xml  \n",
            "  inflating: hololens/train/annotations/image (85).xml  \n",
            "  inflating: hololens/train/annotations/image (86).xml  \n",
            "  inflating: hololens/train/annotations/image (87).xml  \n",
            "  inflating: hololens/train/annotations/image (88).xml  \n",
            "  inflating: hololens/train/annotations/image (89).xml  \n",
            "  inflating: hololens/train/annotations/image (9).xml  \n",
            "  inflating: hololens/train/annotations/image (90).xml  \n",
            "  inflating: hololens/train/annotations/image (91).xml  \n",
            "  inflating: hololens/train/annotations/image (92).xml  \n",
            "  inflating: hololens/train/annotations/image (93).xml  \n",
            "  inflating: hololens/train/annotations/image (94).xml  \n",
            "  inflating: hololens/train/annotations/image (95).xml  \n",
            "  inflating: hololens/train/annotations/image (96).xml  \n",
            "  inflating: hololens/train/annotations/image (97).xml  \n",
            "  inflating: hololens/train/annotations/image (98).xml  \n",
            "  inflating: hololens/train/annotations/image (99).xml  \n",
            "   creating: hololens/train/images/\n",
            "  inflating: hololens/train/images/image (1).jpg  \n",
            "  inflating: hololens/train/images/image (10).jpg  \n",
            "  inflating: hololens/train/images/image (100).jpg  \n",
            "  inflating: hololens/train/images/image (101).jpg  \n",
            "  inflating: hololens/train/images/image (102).jpg  \n",
            "  inflating: hololens/train/images/image (103).jpg  \n",
            "  inflating: hololens/train/images/image (104).jpg  \n",
            "  inflating: hololens/train/images/image (105).jpg  \n",
            "  inflating: hololens/train/images/image (106).jpg  \n",
            "  inflating: hololens/train/images/image (107).jpg  \n",
            "  inflating: hololens/train/images/image (108).jpg  \n",
            "  inflating: hololens/train/images/image (109).jpg  \n",
            "  inflating: hololens/train/images/image (11).jpg  \n",
            "  inflating: hololens/train/images/image (110).jpg  \n",
            "  inflating: hololens/train/images/image (111).jpg  \n",
            "  inflating: hololens/train/images/image (112).jpg  \n",
            "  inflating: hololens/train/images/image (113).jpg  \n",
            "  inflating: hololens/train/images/image (114).jpg  \n",
            "  inflating: hololens/train/images/image (115).jpg  \n",
            "  inflating: hololens/train/images/image (116).jpg  \n",
            "  inflating: hololens/train/images/image (117).jpg  \n",
            "  inflating: hololens/train/images/image (118).jpg  \n",
            "  inflating: hololens/train/images/image (119).jpg  \n",
            "  inflating: hololens/train/images/image (12).jpg  \n",
            "  inflating: hololens/train/images/image (120).jpg  \n",
            "  inflating: hololens/train/images/image (121).jpg  \n",
            "  inflating: hololens/train/images/image (122).jpg  \n",
            "  inflating: hololens/train/images/image (123).jpg  \n",
            "  inflating: hololens/train/images/image (124).jpg  \n",
            "  inflating: hololens/train/images/image (125).jpg  \n",
            "  inflating: hololens/train/images/image (126).jpg  \n",
            "  inflating: hololens/train/images/image (127).jpg  \n",
            "  inflating: hololens/train/images/image (128).jpg  \n",
            "  inflating: hololens/train/images/image (129).jpg  \n",
            "  inflating: hololens/train/images/image (13).jpg  \n",
            "  inflating: hololens/train/images/image (130).jpg  \n",
            "  inflating: hololens/train/images/image (131).jpg  \n",
            "  inflating: hololens/train/images/image (132).jpg  \n",
            "  inflating: hololens/train/images/image (133).jpg  \n",
            "  inflating: hololens/train/images/image (134).jpg  \n",
            "  inflating: hololens/train/images/image (135).jpg  \n",
            "  inflating: hololens/train/images/image (136).jpg  \n",
            "  inflating: hololens/train/images/image (137).jpg  \n",
            "  inflating: hololens/train/images/image (138).jpg  \n",
            "  inflating: hololens/train/images/image (14).jpg  \n",
            "  inflating: hololens/train/images/image (140).jpg  \n",
            "  inflating: hololens/train/images/image (141).jpg  \n",
            "  inflating: hololens/train/images/image (142).jpg  \n",
            "  inflating: hololens/train/images/image (143).jpg  \n",
            "  inflating: hololens/train/images/image (144).jpg  \n",
            "  inflating: hololens/train/images/image (145).jpg  \n",
            "  inflating: hololens/train/images/image (146).jpg  \n",
            "  inflating: hololens/train/images/image (147).jpg  \n",
            "  inflating: hololens/train/images/image (148).jpg  \n",
            "  inflating: hololens/train/images/image (149).jpg  \n",
            "  inflating: hololens/train/images/image (15).jpg  \n",
            "  inflating: hololens/train/images/image (150).jpg  \n",
            "  inflating: hololens/train/images/image (151).jpg  \n",
            "  inflating: hololens/train/images/image (152).jpg  \n",
            "  inflating: hololens/train/images/image (153).jpg  \n",
            "  inflating: hololens/train/images/image (154).jpg  \n",
            "  inflating: hololens/train/images/image (155).jpg  \n",
            "  inflating: hololens/train/images/image (156).jpg  \n",
            "  inflating: hololens/train/images/image (157).jpg  \n",
            "  inflating: hololens/train/images/image (158).jpg  \n",
            "  inflating: hololens/train/images/image (159).jpg  \n",
            "  inflating: hololens/train/images/image (16).jpg  \n",
            "  inflating: hololens/train/images/image (160).jpg  \n",
            "  inflating: hololens/train/images/image (161).jpg  \n",
            "  inflating: hololens/train/images/image (162).jpg  \n",
            "  inflating: hololens/train/images/image (163).jpg  \n",
            "  inflating: hololens/train/images/image (164).jpg  \n",
            "  inflating: hololens/train/images/image (165).jpg  \n",
            "  inflating: hololens/train/images/image (166).jpg  \n",
            "  inflating: hololens/train/images/image (167).jpg  \n",
            "  inflating: hololens/train/images/image (168).jpg  \n",
            "  inflating: hololens/train/images/image (169).jpg  \n",
            "  inflating: hololens/train/images/image (17).jpg  \n",
            "  inflating: hololens/train/images/image (170).jpg  \n",
            "  inflating: hololens/train/images/image (171).jpg  \n",
            "  inflating: hololens/train/images/image (172).jpg  \n",
            "  inflating: hololens/train/images/image (173).jpg  \n",
            "  inflating: hololens/train/images/image (174).jpg  \n",
            "  inflating: hololens/train/images/image (175).jpg  \n",
            "  inflating: hololens/train/images/image (176).jpg  \n",
            "  inflating: hololens/train/images/image (177).jpg  \n",
            "  inflating: hololens/train/images/image (178).jpg  \n",
            "  inflating: hololens/train/images/image (179).jpg  \n",
            "  inflating: hololens/train/images/image (18).jpg  \n",
            "  inflating: hololens/train/images/image (180).jpg  \n",
            "  inflating: hololens/train/images/image (181).jpg  \n",
            "  inflating: hololens/train/images/image (182).jpg  \n",
            "  inflating: hololens/train/images/image (183).jpg  \n",
            "  inflating: hololens/train/images/image (184).jpg  \n",
            "  inflating: hololens/train/images/image (185).jpg  \n",
            "  inflating: hololens/train/images/image (186).jpg  \n",
            "  inflating: hololens/train/images/image (187).jpg  \n",
            "  inflating: hololens/train/images/image (188).jpg  \n",
            "  inflating: hololens/train/images/image (189).jpg  \n",
            "  inflating: hololens/train/images/image (19).jpg  \n",
            "  inflating: hololens/train/images/image (190).jpg  \n",
            "  inflating: hololens/train/images/image (191).jpg  \n",
            "  inflating: hololens/train/images/image (192).jpg  \n",
            "  inflating: hololens/train/images/image (193).jpg  \n",
            "  inflating: hololens/train/images/image (194).jpg  \n",
            "  inflating: hololens/train/images/image (195).jpg  \n",
            "  inflating: hololens/train/images/image (196).jpg  \n",
            "  inflating: hololens/train/images/image (197).jpg  \n",
            "  inflating: hololens/train/images/image (198).jpg  \n",
            "  inflating: hololens/train/images/image (199).jpg  \n",
            "  inflating: hololens/train/images/image (2).jpg  \n",
            "  inflating: hololens/train/images/image (20).jpg  \n",
            "  inflating: hololens/train/images/image (200).jpg  \n",
            "  inflating: hololens/train/images/image (201).jpg  \n",
            "  inflating: hololens/train/images/image (202).jpg  \n",
            "  inflating: hololens/train/images/image (203).jpg  \n",
            "  inflating: hololens/train/images/image (204).jpg  \n",
            "  inflating: hololens/train/images/image (205).jpg  \n",
            "  inflating: hololens/train/images/image (206).jpg  \n",
            "  inflating: hololens/train/images/image (207).jpg  \n",
            "  inflating: hololens/train/images/image (208).jpg  \n",
            "  inflating: hololens/train/images/image (209).jpg  \n",
            "  inflating: hololens/train/images/image (21).jpg  \n",
            "  inflating: hololens/train/images/image (210).jpg  \n",
            "  inflating: hololens/train/images/image (211).jpg  \n",
            "  inflating: hololens/train/images/image (212).jpg  \n",
            "  inflating: hololens/train/images/image (213).jpg  \n",
            "  inflating: hololens/train/images/image (214).jpg  \n",
            "  inflating: hololens/train/images/image (215).jpg  \n",
            "  inflating: hololens/train/images/image (216).jpg  \n",
            "  inflating: hololens/train/images/image (217).jpg  \n",
            "  inflating: hololens/train/images/image (218).jpg  \n",
            "  inflating: hololens/train/images/image (219).jpg  \n",
            "  inflating: hololens/train/images/image (22).jpg  \n",
            "  inflating: hololens/train/images/image (220).jpg  \n",
            "  inflating: hololens/train/images/image (221).jpg  \n",
            "  inflating: hololens/train/images/image (222).jpg  \n",
            "  inflating: hololens/train/images/image (223).jpg  \n",
            "  inflating: hololens/train/images/image (224).jpg  \n",
            "  inflating: hololens/train/images/image (225).jpg  \n",
            "  inflating: hololens/train/images/image (226).jpg  \n",
            "  inflating: hololens/train/images/image (227).jpg  \n",
            "  inflating: hololens/train/images/image (228).jpg  \n",
            "  inflating: hololens/train/images/image (229).jpg  \n",
            "  inflating: hololens/train/images/image (23).jpg  \n",
            "  inflating: hololens/train/images/image (230).jpg  \n",
            "  inflating: hololens/train/images/image (231).jpg  \n",
            "  inflating: hololens/train/images/image (232).jpg  \n",
            "  inflating: hololens/train/images/image (233).jpg  \n",
            "  inflating: hololens/train/images/image (234).jpg  \n",
            "  inflating: hololens/train/images/image (235).jpg  \n",
            "  inflating: hololens/train/images/image (236).jpg  \n",
            "  inflating: hololens/train/images/image (237).jpg  \n",
            "  inflating: hololens/train/images/image (238).jpg  \n",
            "  inflating: hololens/train/images/image (239).jpg  \n",
            "  inflating: hololens/train/images/image (24).jpg  \n",
            "  inflating: hololens/train/images/image (240).jpg  \n",
            "  inflating: hololens/train/images/image (241).jpg  \n",
            "  inflating: hololens/train/images/image (25).jpg  \n",
            "  inflating: hololens/train/images/image (26).jpg  \n",
            "  inflating: hololens/train/images/image (27).jpg  \n",
            "  inflating: hololens/train/images/image (28).jpg  \n",
            "  inflating: hololens/train/images/image (29).jpg  \n",
            "  inflating: hololens/train/images/image (3).jpg  \n",
            "  inflating: hololens/train/images/image (30).jpg  \n",
            "  inflating: hololens/train/images/image (31).jpg  \n",
            "  inflating: hololens/train/images/image (32).jpg  \n",
            "  inflating: hololens/train/images/image (33).jpg  \n",
            "  inflating: hololens/train/images/image (34).jpg  \n",
            "  inflating: hololens/train/images/image (35).jpg  \n",
            "  inflating: hololens/train/images/image (36).jpg  \n",
            "  inflating: hololens/train/images/image (37).jpg  \n",
            "  inflating: hololens/train/images/image (38).jpg  \n",
            "  inflating: hololens/train/images/image (39).jpg  \n",
            "  inflating: hololens/train/images/image (4).jpg  \n",
            "  inflating: hololens/train/images/image (40).jpg  \n",
            "  inflating: hololens/train/images/image (41).jpg  \n",
            "  inflating: hololens/train/images/image (42).jpg  \n",
            "  inflating: hololens/train/images/image (43).jpg  \n",
            "  inflating: hololens/train/images/image (44).jpg  \n",
            "  inflating: hololens/train/images/image (45).jpg  \n",
            "  inflating: hololens/train/images/image (46).jpg  \n",
            "  inflating: hololens/train/images/image (47).jpg  \n",
            "  inflating: hololens/train/images/image (48).jpg  \n",
            "  inflating: hololens/train/images/image (49).jpg  \n",
            "  inflating: hololens/train/images/image (5).jpg  \n",
            "  inflating: hololens/train/images/image (50).jpg  \n",
            "  inflating: hololens/train/images/image (51).jpg  \n",
            "  inflating: hololens/train/images/image (52).jpg  \n",
            "  inflating: hololens/train/images/image (53).jpg  \n",
            "  inflating: hololens/train/images/image (54).jpg  \n",
            "  inflating: hololens/train/images/image (55).jpg  \n",
            "  inflating: hololens/train/images/image (56).jpg  \n",
            "  inflating: hololens/train/images/image (57).jpg  \n",
            "  inflating: hololens/train/images/image (58).jpg  \n",
            "  inflating: hololens/train/images/image (59).jpg  \n",
            " extracting: hololens/train/images/image (6).jpg  \n",
            "  inflating: hololens/train/images/image (60).jpg  \n",
            "  inflating: hololens/train/images/image (61).jpg  \n",
            "  inflating: hololens/train/images/image (62).jpg  \n",
            "  inflating: hololens/train/images/image (63).jpg  \n",
            "  inflating: hololens/train/images/image (64).jpg  \n",
            "  inflating: hololens/train/images/image (65).jpg  \n",
            "  inflating: hololens/train/images/image (66).jpg  \n",
            "  inflating: hololens/train/images/image (67).jpg  \n",
            "  inflating: hololens/train/images/image (68).jpg  \n",
            "  inflating: hololens/train/images/image (69).jpg  \n",
            "  inflating: hololens/train/images/image (7).jpg  \n",
            "  inflating: hololens/train/images/image (70).jpg  \n",
            "  inflating: hololens/train/images/image (71).jpg  \n",
            "  inflating: hololens/train/images/image (72).jpg  \n",
            "  inflating: hololens/train/images/image (73).jpg  \n",
            "  inflating: hololens/train/images/image (74).jpg  \n",
            "  inflating: hololens/train/images/image (75).jpg  \n",
            "  inflating: hololens/train/images/image (76).jpg  \n",
            "  inflating: hololens/train/images/image (77).jpg  \n",
            "  inflating: hololens/train/images/image (78).jpg  \n",
            "  inflating: hololens/train/images/image (79).jpg  \n",
            "  inflating: hololens/train/images/image (8).jpg  \n",
            "  inflating: hololens/train/images/image (80).jpg  \n",
            "  inflating: hololens/train/images/image (81).jpg  \n",
            "  inflating: hololens/train/images/image (82).jpg  \n",
            "  inflating: hololens/train/images/image (83).jpg  \n",
            "  inflating: hololens/train/images/image (84).jpg  \n",
            "  inflating: hololens/train/images/image (85).jpg  \n",
            "  inflating: hololens/train/images/image (86).jpg  \n",
            "  inflating: hololens/train/images/image (87).jpg  \n",
            "  inflating: hololens/train/images/image (88).jpg  \n",
            "  inflating: hololens/train/images/image (89).jpg  \n",
            "  inflating: hololens/train/images/image (9).jpg  \n",
            "  inflating: hololens/train/images/image (90).jpg  \n",
            "  inflating: hololens/train/images/image (91).jpg  \n",
            "  inflating: hololens/train/images/image (92).jpg  \n",
            "  inflating: hololens/train/images/image (93).jpg  \n",
            "  inflating: hololens/train/images/image (94).jpg  \n",
            "  inflating: hololens/train/images/image (95).jpg  \n",
            "  inflating: hololens/train/images/image (96).jpg  \n",
            "  inflating: hololens/train/images/image (97).jpg  \n",
            "  inflating: hololens/train/images/image (98).jpg  \n",
            "  inflating: hololens/train/images/image (99).jpg  \n",
            "   creating: hololens/validation/\n",
            "   creating: hololens/validation/annotations/\n",
            "  inflating: hololens/validation/annotations/image (242).xml  \n",
            "  inflating: hololens/validation/annotations/image (243).xml  \n",
            "  inflating: hololens/validation/annotations/image (244).xml  \n",
            "  inflating: hololens/validation/annotations/image (245).xml  \n",
            "  inflating: hololens/validation/annotations/image (246).xml  \n",
            "  inflating: hololens/validation/annotations/image (247).xml  \n",
            "  inflating: hololens/validation/annotations/image (248).xml  \n",
            "  inflating: hololens/validation/annotations/image (249).xml  \n",
            "  inflating: hololens/validation/annotations/image (250).xml  \n",
            "  inflating: hololens/validation/annotations/image (251).xml  \n",
            "  inflating: hololens/validation/annotations/image (252).xml  \n",
            "  inflating: hololens/validation/annotations/image (253).xml  \n",
            "  inflating: hololens/validation/annotations/image (254).xml  \n",
            "  inflating: hololens/validation/annotations/image (255).xml  \n",
            "  inflating: hololens/validation/annotations/image (256).xml  \n",
            "  inflating: hololens/validation/annotations/image (257).xml  \n",
            "  inflating: hololens/validation/annotations/image (258).xml  \n",
            "  inflating: hololens/validation/annotations/image (259).xml  \n",
            "  inflating: hololens/validation/annotations/image (260).xml  \n",
            "  inflating: hololens/validation/annotations/image (261).xml  \n",
            "  inflating: hololens/validation/annotations/image (262).xml  \n",
            "  inflating: hololens/validation/annotations/image (263).xml  \n",
            "  inflating: hololens/validation/annotations/image (264).xml  \n",
            "  inflating: hololens/validation/annotations/image (265).xml  \n",
            "  inflating: hololens/validation/annotations/image (266).xml  \n",
            "  inflating: hololens/validation/annotations/image (267).xml  \n",
            "  inflating: hololens/validation/annotations/image (268).xml  \n",
            "  inflating: hololens/validation/annotations/image (269).xml  \n",
            "  inflating: hololens/validation/annotations/image (270).xml  \n",
            "  inflating: hololens/validation/annotations/image (271).xml  \n",
            "  inflating: hololens/validation/annotations/image (272).xml  \n",
            "  inflating: hololens/validation/annotations/image (273).xml  \n",
            "  inflating: hololens/validation/annotations/image (274).xml  \n",
            "  inflating: hololens/validation/annotations/image (275).xml  \n",
            "  inflating: hololens/validation/annotations/image (276).xml  \n",
            "  inflating: hololens/validation/annotations/image (277).xml  \n",
            "  inflating: hololens/validation/annotations/image (278).xml  \n",
            "  inflating: hololens/validation/annotations/image (279).xml  \n",
            "  inflating: hololens/validation/annotations/image (280).xml  \n",
            "  inflating: hololens/validation/annotations/image (281).xml  \n",
            "  inflating: hololens/validation/annotations/image (282).xml  \n",
            "  inflating: hololens/validation/annotations/image (283).xml  \n",
            "  inflating: hololens/validation/annotations/image (284).xml  \n",
            "  inflating: hololens/validation/annotations/image (285).xml  \n",
            "  inflating: hololens/validation/annotations/image (286).xml  \n",
            "  inflating: hololens/validation/annotations/image (287).xml  \n",
            "  inflating: hololens/validation/annotations/image (288).xml  \n",
            "  inflating: hololens/validation/annotations/image (289).xml  \n",
            "  inflating: hololens/validation/annotations/image (290).xml  \n",
            "  inflating: hololens/validation/annotations/image (291).xml  \n",
            "  inflating: hololens/validation/annotations/image (292).xml  \n",
            "  inflating: hololens/validation/annotations/image (293).xml  \n",
            "  inflating: hololens/validation/annotations/image (294).xml  \n",
            "  inflating: hololens/validation/annotations/image (295).xml  \n",
            "  inflating: hololens/validation/annotations/image (296).xml  \n",
            "  inflating: hololens/validation/annotations/image (297).xml  \n",
            "  inflating: hololens/validation/annotations/image (298).xml  \n",
            "  inflating: hololens/validation/annotations/image (299).xml  \n",
            "  inflating: hololens/validation/annotations/image (300).xml  \n",
            "   creating: hololens/validation/images/\n",
            "  inflating: hololens/validation/images/image (242).jpg  \n",
            "  inflating: hololens/validation/images/image (243).jpg  \n",
            "  inflating: hololens/validation/images/image (244).jpg  \n",
            "  inflating: hololens/validation/images/image (245).jpg  \n",
            "  inflating: hololens/validation/images/image (246).jpg  \n",
            "  inflating: hololens/validation/images/image (247).jpg  \n",
            "  inflating: hololens/validation/images/image (248).jpg  \n",
            "  inflating: hololens/validation/images/image (249).jpg  \n",
            "  inflating: hololens/validation/images/image (250).jpg  \n",
            "  inflating: hololens/validation/images/image (251).jpg  \n",
            "  inflating: hololens/validation/images/image (252).jpg  \n",
            "  inflating: hololens/validation/images/image (253).jpg  \n",
            "  inflating: hololens/validation/images/image (254).jpg  \n",
            "  inflating: hololens/validation/images/image (255).jpg  \n",
            "  inflating: hololens/validation/images/image (256).jpg  \n",
            "  inflating: hololens/validation/images/image (257).jpg  \n",
            "  inflating: hololens/validation/images/image (258).jpg  \n",
            "  inflating: hololens/validation/images/image (259).jpg  \n",
            "  inflating: hololens/validation/images/image (260).jpg  \n",
            "  inflating: hololens/validation/images/image (261).jpg  \n",
            "  inflating: hololens/validation/images/image (262).jpg  \n",
            "  inflating: hololens/validation/images/image (263).jpg  \n",
            "  inflating: hololens/validation/images/image (264).jpg  \n",
            "  inflating: hololens/validation/images/image (265).jpg  \n",
            "  inflating: hololens/validation/images/image (266).jpg  \n",
            "  inflating: hololens/validation/images/image (267).jpg  \n",
            "  inflating: hololens/validation/images/image (268).jpg  \n",
            "  inflating: hololens/validation/images/image (269).jpg  \n",
            "  inflating: hololens/validation/images/image (270).jpg  \n",
            "  inflating: hololens/validation/images/image (271).jpg  \n",
            "  inflating: hololens/validation/images/image (272).jpg  \n",
            "  inflating: hololens/validation/images/image (273).jpg  \n",
            "  inflating: hololens/validation/images/image (274).jpg  \n",
            "  inflating: hololens/validation/images/image (275).jpg  \n",
            "  inflating: hololens/validation/images/image (276).jpg  \n",
            "  inflating: hololens/validation/images/image (277).jpg  \n",
            "  inflating: hololens/validation/images/image (278).jpg  \n",
            "  inflating: hololens/validation/images/image (279).jpg  \n",
            "  inflating: hololens/validation/images/image (280).jpg  \n",
            "  inflating: hololens/validation/images/image (281).jpg  \n",
            "  inflating: hololens/validation/images/image (282).jpg  \n",
            "  inflating: hololens/validation/images/image (283).jpg  \n",
            "  inflating: hololens/validation/images/image (284).jpg  \n",
            "  inflating: hololens/validation/images/image (285).jpg  \n",
            "  inflating: hololens/validation/images/image (286).jpg  \n",
            "  inflating: hololens/validation/images/image (287).jpg  \n",
            "  inflating: hololens/validation/images/image (288).jpg  \n",
            "  inflating: hololens/validation/images/image (289).jpg  \n",
            "  inflating: hololens/validation/images/image (290).jpg  \n",
            "  inflating: hololens/validation/images/image (291).jpg  \n",
            "  inflating: hololens/validation/images/image (292).jpg  \n",
            "  inflating: hololens/validation/images/image (293).jpg  \n",
            "  inflating: hololens/validation/images/image (294).jpg  \n",
            "  inflating: hololens/validation/images/image (295).jpg  \n",
            "  inflating: hololens/validation/images/image (296).jpg  \n",
            "  inflating: hololens/validation/images/image (297).jpg  \n",
            "  inflating: hololens/validation/images/image (298).jpg  \n",
            "  inflating: hololens/validation/images/image (299).jpg  \n",
            "  inflating: hololens/validation/images/image (300).jpg  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOG_vtA8NcjT"
      },
      "source": [
        "## 3. Optional: Download a pretrain model\n",
        "If we have a pretrain model, we could use transfer learning and then speed up the traing procedure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZshF2e2tKTDq"
      },
      "source": [
        "# !wget https://github.com/OlafenwaMoses/ImageAI/releases/download/essential-v4/pretrained-yolov3.h5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kb60dJKJlwS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "245d1092-bcfb-481a-cca5-44de0ce09fa6"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mhololens\u001b[0m/  hololens.zip  hololens.zip.1  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSIkmq2hNjcj"
      },
      "source": [
        "## 4. Start the trainning now\n",
        "The first experiment takes 360 to 669 seconds (depended on the batch size you set). The next step spends 300 to 405 seconds. If we use 200 epochs, we roughly needs 22 hours. Please note that we download a pretrain model in the program."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ws3nDbtmJc7S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 796
        },
        "outputId": "7dcb1e43-ce58-4277-e274-f0471dec81fe"
      },
      "source": [
        "from imageai.Detection.Custom import DetectionModelTrainer\n",
        "\n",
        "trainer = DetectionModelTrainer()\n",
        "trainer.setModelTypeAsYOLOv3()\n",
        "trainer.setDataDirectory(data_directory=\"hololens\")\n",
        "# trainer.setTrainConfig(object_names_array=[\"hololens\"], batch_size=8, num_experiments=5, train_from_pretrained_model=\"pretrained-yolov3.h5\")\n",
        "trainer.setTrainConfig(object_names_array=[\"hololens\"], batch_size=8, num_experiments=5)\n",
        "trainer.trainModel()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Generating anchor boxes for training images and annotation...\n",
            "Average IOU for 9 anchors: 0.77\n",
            "Anchor Boxes generated.\n",
            "Detection configuration saved in  hololens/json/detection_config.json\n",
            "Training on: \t['hololens']\n",
            "Training with Batch Size:  8\n",
            "Number of Experiments:  5\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/imageai/Detection/Custom/yolo.py:24: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Pre-trained Model not provided. Transfer learning not in use.\n",
            "Training will start with 3 warmup experiments\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:998: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
            "  warnings.warn('`epsilon` argument is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/8\n",
            "240/240 [==============================] - 434s 2s/step - loss: 238.2919 - yolo_layer_1_loss: 35.2984 - yolo_layer_2_loss: 69.4272 - yolo_layer_3_loss: 133.5662 - val_loss: 61.5482 - val_yolo_layer_1_loss: 6.8486 - val_yolo_layer_2_loss: 15.3021 - val_yolo_layer_3_loss: 29.3907\n",
            "Epoch 2/8\n",
            "240/240 [==============================] - 334s 1s/step - loss: 41.6967 - yolo_layer_1_loss: 7.7065 - yolo_layer_2_loss: 13.7968 - yolo_layer_3_loss: 20.1934 - val_loss: 41.8419 - val_yolo_layer_1_loss: 10.6119 - val_yolo_layer_2_loss: 14.2048 - val_yolo_layer_3_loss: 16.4096\n",
            "Epoch 3/8\n",
            "240/240 [==============================] - 336s 1s/step - loss: 29.7551 - yolo_layer_1_loss: 6.6321 - yolo_layer_2_loss: 11.2141 - yolo_layer_3_loss: 11.9089 - val_loss: 26.0874 - val_yolo_layer_1_loss: 10.5723 - val_yolo_layer_2_loss: 10.4065 - val_yolo_layer_3_loss: 8.9534\n",
            "Epoch 4/8\n",
            " 80/240 [=========>....................] - ETA: 3:06 - loss: 24.6976 - yolo_layer_1_loss: 5.7053 - yolo_layer_2_loss: 10.0536 - yolo_layer_3_loss: 8.9388"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMI1lb8uMhDP"
      },
      "source": [
        "## 5. Model Evaluation\n",
        "It shows the mAP of our trained models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcFoyICQMjVP"
      },
      "source": [
        "from imageai.Detection.Custom import DetectionModelTrainer\n",
        "\n",
        "trainer = DetectionModelTrainer()\n",
        "trainer.setModelTypeAsYOLOv3()\n",
        "trainer.setDataDirectory(data_directory=\"hololens\")\n",
        "trainer.evaluateModel(model_path=\"hololens/models\", json_path=\"hololens/json/detection_config.json\", iou_threshold=0.5, object_threshold=0.3, nms_threshold=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mmthG-_N1Qp"
      },
      "source": [
        "## 6. Testing the trained model\n",
        "We should select a trained model manually. However, in order to let the program to be ran without any modification, we use the model instead. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4dzRKBrSmu1"
      },
      "source": [
        "import glob\n",
        "import os\n",
        "\n",
        "list_of_files = glob.glob('hololens/models/*') # * means all if need specific format then *.csv\n",
        "latest_model = max(list_of_files, key=os.path.getctime)\n",
        "print(latest_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yg89M2_4ngUb"
      },
      "source": [
        "Download a testing figure from internet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTgYye1wLcNe"
      },
      "source": [
        "!wget https://mspoweruser.com/wp-content/uploads/2018/10/hololens-festival.jpg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAyxHNySUB1w"
      },
      "source": [
        "from imageai.Detection.Custom import CustomObjectDetection\n",
        "\n",
        "detector = CustomObjectDetection()\n",
        "detector.setModelTypeAsYOLOv3()\n",
        "detector.setModelPath(latest_model)\n",
        "detector.setJsonPath(\"hololens/json/detection_config.json\")\n",
        "detector.loadModel()\n",
        "detections = detector.detectObjectsFromImage(input_image=\"hololens-festival.jpg\", output_image_path=\"holo2-detected.jpg\")\n",
        "for detection in detections:\n",
        "    print(detection[\"name\"], \" : \", detection[\"percentage_probability\"], \" : \", detection[\"box_points\"])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}